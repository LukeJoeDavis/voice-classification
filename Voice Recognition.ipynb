{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import scipy\n",
    "from bs4 import *\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # with urllib.request.urlopen(\"https://librivox.org/search?primary_key=0&search_category=title&search_page=1&search_form=get_results\") as url:\n",
    "# #     html = url.read()\n",
    "\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# names = []\n",
    "# temp_name = \"\"\n",
    "# temp_size = \"\"\n",
    "# counter = 1\n",
    "# for i in range(1, 220):\n",
    "#     print(i)\n",
    "#     url = \"https://librivox.org/search?title=&author=&reader=&keywords=&genre_id=0&status=all&project_type=solo&recorded_language=&sort_order=catalog_date&search_page={}&search_form=advanced\".format(i)\n",
    "#     browser = webdriver.PhantomJS(r'''C:\\phantomjs-2.1.1-windows\\bin\\phantomjs''')\n",
    "#     browser.get(url)\n",
    "\n",
    "#     element = WebDriverWait(browser, 10).until(\n",
    "#         EC.presence_of_element_located((By.CLASS_NAME , \"catalog-result\"))\n",
    "#     )\n",
    "\n",
    "#     html = browser.page_source\n",
    "#     soup = BeautifulSoup(html, 'html5lib')    \n",
    "\n",
    "#     links = []\n",
    "# #     for ultag in soup.find_all('ul', {'class': 'browse-list'}):\n",
    "#     for litag in ultag.find_all('li', {'class': 'catalog-result'}):\n",
    "#         for l in litag.find_all('div', {'class': 'result-data'}):\n",
    "#             for h in l.find_all('h3'):\n",
    "\n",
    "# #                     print(h.a['href'])\n",
    "#                 browser.get(h.a['href'])\n",
    "#                 html2 = browser.page_source\n",
    "#                 soup2 = BeautifulSoup(html2, 'html5lib')\n",
    "\n",
    "#                 for sidebars in soup2.find_all('div', {'class': 'sidebar'}):\n",
    "#                     for s in sidebars.find_all('dl', {'class': 'product-details'}):\n",
    "#                         target =  s.find_all('dd')\n",
    "#                         temp_name = target[3].get_text()\n",
    "#                         print(temp_name)\n",
    "#                         temp_size = target[1].get_text()\n",
    "#                         temp_size = temp_size.replace('MB','')\n",
    "\n",
    "#                         if(temp_name in names):\n",
    "#                             break\n",
    "\n",
    "#                         for s in sidebars.find_all('dl', {'class': 'product-details'}):\n",
    "#                             target = sidebars.find_all('dl', {'class': 'listen-download'})\n",
    "#                             if float(temp_size) >= 25 and float(temp_size) <= 110: links.append(target[0].a['href'])\n",
    "\n",
    "#                         names.append(temp_name)\n",
    "\n",
    "                                \n",
    "# #             for dtag in litag.find_all('dt'):\n",
    "# #             #                 print(dtag.span.text)\n",
    "# #             #                 print(dtag.a['href'])\n",
    "# #                 x = dtag.span.text\n",
    "# #                 x = x.replace('MB','')\n",
    "# #                 if float(x) >= 25 and float(x) <= 110:\n",
    "# #                         links.append(dtag.a['href'])\n",
    "#     browser.quit()\n",
    "# #     print(names)\n",
    "# #     for link in links:\n",
    "# #         localDestination = \"C:/Users/Yousef/PycharmProjects/EE379K/Voice Recognition/audio/audio{}.zip\".format(counter)\n",
    "# #         resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n",
    "# #         counter += 1\n",
    "        \n",
    "# ## Start at page 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "VfkaBT\n",
      "John Van Stan\n",
      "Newgatenovelist\n",
      "Nemo\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Algy Pug\n",
      "Renzo Clerico\n",
      "David Wales\n",
      "7\n",
      "Phil Chenevert\n",
      "Sue Anderson\n",
      "Pamela Nagami\n",
      "Geremia\n",
      "8\n",
      "gadhbteo7\n",
      "Peter Tucker\n",
      "9\n",
      "Delmar H Dolbier\n",
      "Lynda Marie Neilson\n",
      "Peter Thomlinson\n",
      "Jude Somers\n",
      "10\n",
      "KHand\n",
      "progressingamerica\n",
      "karampas1968\n",
      "11\n",
      "Mark Nelson\n",
      "Ἑλένη Κεμικτσή\n",
      "NoelBadrian\n",
      "RogerioM\n",
      "Nicole Lee\n",
      "Aaron Rivera\n",
      "Roger Melin\n",
      "Expatriate\n",
      "12\n",
      "Victor Villarraza\n",
      "Crln Yldz Ksr\n",
      "Arthur Krolman\n",
      "Phil Schempf\n",
      "13\n",
      "DrPGould\n",
      "Availle\n",
      "Michael Fassio\n",
      "Eva K.\n",
      "Phil Benson\n",
      "14\n",
      "A LibriVox Volunteer\n",
      "15\n",
      "annie70\n",
      "John\n",
      "Sonnie Abdalla\n",
      "16\n",
      "Devorah Allen\n",
      "Omri Lernau\n",
      "Patrick Saville\n",
      "Jeffery\n",
      "Eva Davis\n",
      "17\n",
      "Kristel Tretter\n",
      "Maria Sozopoulou\n",
      "Peter Eastman\n",
      "18\n",
      "Steve C\n",
      "Amelia Chesley\n",
      "Linette Geisel\n",
      "Lee Smalley\n",
      "19\n",
      "Greg Giordano\n",
      "sv1637\n",
      "20\n",
      "Scotty Smith\n",
      "Scott Danneker\n",
      "21\n",
      "Hatton43\n",
      "22\n",
      "Mongope\n",
      "mlcui\n",
      "Landon D. C. Elkind\n",
      "Nicholas Clifford\n",
      "23\n",
      "Leon Harvey\n",
      "Jael Baldwin\n",
      "Lynne T\n",
      "Gosia Leksandrówna\n",
      "24\n",
      "Loren Eaton\n",
      "mariemdover\n",
      "W. Blaine Dowler\n",
      "25\n",
      "Harri Tapani Ylilammi\n",
      "26\n",
      "Jordan Watts\n",
      "Jill Engle\n",
      "Kevin Green\n",
      "27\n",
      "Winston Tharp\n",
      "storylines\n",
      "Sonia\n",
      "Vivienne Wong\n",
      "28\n",
      "EvanJ\n",
      "clarinetcarrot\n",
      "Holly Jenson\n",
      "Clive Catterall\n",
      "29\n",
      "Tess Leigh\n",
      "Barbara Baker\n",
      "MaryAnn\n",
      "Ærik Bjørnsson\n",
      "30\n",
      "pejuga\n",
      "Rosslyn Carlyle\n",
      "Glenn O'Brien\n",
      "Scarlett Martin\n",
      "31\n",
      "Laurie Anne Walden\n",
      "Paul Rizik\n",
      "Ethan D. Gilkey\n",
      "32\n",
      "Eddie Frierson\n",
      "Subhash Chander\n",
      "33\n",
      "Curt Walton\n",
      "34\n",
      "Tony Addison\n",
      "35\n",
      "36\n",
      "Maria Therese\n",
      "Anusha Iyer\n",
      "37\n",
      "Anastasiia Solokha\n",
      "38\n",
      "P. J. Taylor\n",
      "Ed Humpal\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e23d8f19a784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mlocalDestination\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/Yousef/PycharmProjects/EE379K/Voice Recognition/audio/audio{}.wav\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mresultFilePath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponseHeaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocalDestination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with urllib.request.urlopen(\"https://librivox.org/search?primary_key=0&search_category=title&search_page=1&search_form=get_results\") as url:\n",
    "#     html = url.read()\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "names = []\n",
    "temp_name = \"\"\n",
    "temp_size = \"\"\n",
    "counter = 1\n",
    "for i in range(1, 220):\n",
    "    print(i)\n",
    "    url = \"https://librivox.org/search?title=&author=&reader=&keywords=&genre_id=0&status=all&project_type=solo&recorded_language=&sort_order=catalog_date&search_page={}&search_form=advanced\".format(i)\n",
    "    browser = webdriver.PhantomJS(r'''C:\\phantomjs-2.1.1-windows\\bin\\phantomjs''')\n",
    "    browser.get(url)\n",
    "\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME , \"catalog-result\"))\n",
    "    )\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html5lib')    \n",
    "\n",
    "    links = []\n",
    "    for litag in soup.find_all('li', {'class': 'catalog-result'}):\n",
    "        h = litag.find('h3')\n",
    "        browser.get(h.a['href'])\n",
    "        html2 = browser.page_source\n",
    "        soup2 = BeautifulSoup(html2, 'html5lib')\n",
    "\n",
    "        s = soup2.find('dl', {'class': 'product-details'})\n",
    "            \n",
    "        target =  s.find_all('dd')\n",
    "        \n",
    "        temp_name = target[3].get_text()\n",
    "        temp_size = target[1].get_text()\n",
    "        temp_size = temp_size.replace('MB','')\n",
    "\n",
    "        if(temp_name in names):\n",
    "            continue\n",
    "\n",
    "        s = soup2.find('dl', {'class': 'listen-download'})\n",
    "        \n",
    "        target = s.find_all('dd')\n",
    "        \n",
    "        if float(temp_size) >= 25 and float(temp_size) <= 110:\n",
    "            links.append(target[0].a['href'])\n",
    "            names.append(temp_name)\n",
    "            print(temp_name)\n",
    "\n",
    "                                \n",
    "#             for dtag in litag.find_all('dt'):\n",
    "#             #                 print(dtag.span.text)\n",
    "#             #                 print(dtag.a['href'])\n",
    "#                 x = dtag.span.text\n",
    "#                 x = x.replace('MB','')\n",
    "#                 if float(x) >= 25 and float(x) <= 110:\n",
    "#                         links.append(dtag.a['href'])\n",
    "    browser.quit()\n",
    "#     print(names)\n",
    "    for link in links:\n",
    "        localDestination = \"C:/Users/Yousef/PycharmProjects/EE379K/Voice Recognition/audio/audio{}.wav\".format(counter)\n",
    "        resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n",
    "        counter += 1\n",
    "        \n",
    "## Start at page 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "for i in range(1, 106):\n",
    "    zipTest = ZipFile(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}.zip'''.format(i), 'r')\n",
    "    zipTest.extractall(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}'''.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AudioSegment.converter = r\"C:\\\\ffmpeg\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "# for i in range(1, 106):\n",
    "#     files = listdir(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}'''.format(i))\n",
    "    \n",
    "#     if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i)):\n",
    "#         os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i))\n",
    "    \n",
    "#     count = 1\n",
    "#     for f in files:\n",
    "#         sound = AudioSegment.from_mp3(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}\\{}'''.format(i, f))\n",
    "#         out_f = sound.export(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}\\{}.wav'''.format(i, count), format=\"wav\")\n",
    "#         out_f.close()\n",
    "#         count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "for i in range(2, 101):\n",
    "    files = listdir(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i))\n",
    "    \n",
    "    if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i)):\n",
    "        os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i))\n",
    "    \n",
    "    count = 1\n",
    "    limit = 0\n",
    "    for f in files:\n",
    "        if(limit == 720): break\n",
    "        sound = AudioSegment.from_mp3(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}\\{}'''.format(i, f))\n",
    "        out_f = sound.export(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}\\{}.wav'''.format(i, count), format=\"wav\")\n",
    "        out_f.close()\n",
    "        count = count + 1\n",
    "        limit = limit + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import subprocess\n",
    "\n",
    "# c = 'ffmpeg -i \"{}\" -acodec pcm_u8 -ar song.wav'.format(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav1\\out000.wav''')\n",
    "# subprocess.call(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AudioSegment.converter = r\"C:\\\\ffmpeg\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "# for i in range(1, 106):\n",
    "#     files = listdir(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i))\n",
    "    \n",
    "#     if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i)):\n",
    "#         os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i))\n",
    "    \n",
    "#     count1 = 1\n",
    "#     total_length = 0\n",
    "#     for f in files:\n",
    "#         t1 = 0\n",
    "#         t2 = 5000\n",
    "\n",
    "#         newAudio = AudioSegment.from_wav(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}\\{}.wav'''.format(i, count1))\n",
    "#         length = newAudio.duration_seconds * 1000\n",
    "#         total_length = total_length + length\n",
    "        \n",
    "#         count2 = 1\n",
    "#         while t2 <= length:\n",
    "#             x = newAudio[t1:t2]\n",
    "#             out_f = x.export(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}\\{}_{}.wav'''.format(i, count1, count2), format=\"wav\")\n",
    "#             out_f.close()\n",
    "#             t1 = t2 #Works in milliseconds\n",
    "#             t2 = t2 + 5000 # 10 seconds\n",
    "#             count2 = count2 + 1\n",
    "#         count1 = count1 + 1\n",
    "#         if(total_length > 3600000): # one hour\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for i in range(1,101):\n",
    "    in_path = 'C:/Users/Yousef/PycharmProjects/EE379K/Voice Recognition/audio/audio{}.wav'.format(i)\n",
    "    \n",
    "    if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i)):\n",
    "        os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i))\n",
    "    \n",
    "    out_path = 'C:/Users/Yousef/PycharmProjects/EE379K/Voice Recognition/wavs/wav{}/out%03d.wav'.format(i)\n",
    "\n",
    "    subprocess.call(['ffmpeg', '-i', in_path, '-f', 'segment', \n",
    "                   '-segment_time', '5', '-c', 'copy', out_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Turn Audio to Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X,sr = librosa.load(fp)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "\n",
    "def plot_specgram(raw_sounds):\n",
    "#     fig = plt.figure()\n",
    "#     fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    for f in raw_sounds:\n",
    "        plt.subplots(1)\n",
    "#         plt.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "#         plt.margins(x=0)\n",
    "        specgram(np.array(f), Fs=sr)\n",
    "#         plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "#         plt.show()\n",
    "        plt.savefig(\"test.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sound_file_paths = glob.glob(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav1\\*.wav''')\n",
    "\n",
    "# raw_sounds = load_sound_files(sound_file_paths[:1])\n",
    "# plot_specgram(raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# 513 800 3\n",
    "for i in range(89, 101):\n",
    "    files = listdir(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i))\n",
    "    \n",
    "    if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\spectrograms\\speaker{}'''.format(i)):\n",
    "        os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\spectrograms\\speaker{}'''.format(i))\n",
    "    \n",
    "    count = 1\n",
    "    for f in files:\n",
    "        cmdstring = 'sox \"{}\" -n spectrogram -r -o \"{}\"'.format(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}\\{}'''.format(i, f), r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\spectrograms\\speaker{}\\{}.png'''.format(i, count))\n",
    "        subprocess.call(cmdstring, shell=True)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cmdstring = 'sox \"{}\" -n spectrogram -r -o \"{}\"'.format(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav1\\1.wav''', r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\1.png''')\n",
    "# subprocess.call(cmdstring, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
