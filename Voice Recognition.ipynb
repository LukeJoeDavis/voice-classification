{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import scipy\n",
    "from bs4 import *\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with urllib.request.urlopen(\"https://librivox.org/search?primary_key=0&search_category=title&search_page=1&search_form=get_results\") as url:\n",
    "#     html = url.read()\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "counter = 27\n",
    "for i in range(3, 455):\n",
    "    print(i)\n",
    "    url = \"https://librivox.org/search?primary_key=0&search_category=title&search_page={}&search_form=get_results\".format(i)\n",
    "    browser = webdriver.PhantomJS(r'''C:\\phantomjs-2.1.1-windows\\bin\\phantomjs''')\n",
    "    browser.get(url)\n",
    "\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME , \"catalog-result\"))\n",
    "    )\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html5lib')    \n",
    "\n",
    "    links = []\n",
    "    for ultag in soup.find_all('ul', {'class': 'browse-list'}):\n",
    "        for litag in ultag.find_all('li', {'class': 'catalog-result'}):\n",
    "                 for dtag in litag.find_all('div', {'class': 'download-btn'}):\n",
    "    #                 print(dtag.span.text)\n",
    "    #                 print(dtag.a['href'])\n",
    "                    x = dtag.span.text\n",
    "                    x = x.replace('MB','')\n",
    "                    if float(x) >= 50 and float(x) <= 200:\n",
    "                        links.append(dtag.a['href'])\n",
    "    browser.quit()\n",
    "    \n",
    "    for link in links:\n",
    "        localDestination = \"./audio/audio{}.zip\".format(counter)\n",
    "        resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n",
    "        counter += 1\n",
    "        \n",
    "## Start at page 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
