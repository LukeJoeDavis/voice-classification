{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import scipy\n",
    "from bs4 import *\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with urllib.request.urlopen(\"https://librivox.org/search?primary_key=0&search_category=title&search_page=1&search_form=get_results\") as url:\n",
    "#     html = url.read()\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "counter = 27\n",
    "for i in range(3, 455):\n",
    "    print(i)\n",
    "    url = \"https://librivox.org/search?primary_key=0&search_category=title&search_page={}&search_form=get_results\".format(i)\n",
    "    browser = webdriver.PhantomJS(r'''C:\\phantomjs-2.1.1-windows\\bin\\phantomjs''')\n",
    "    browser.get(url)\n",
    "\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME , \"catalog-result\"))\n",
    "    )\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html5lib')    \n",
    "\n",
    "    links = []\n",
    "    for ultag in soup.find_all('ul', {'class': 'browse-list'}):\n",
    "        for litag in ultag.find_all('li', {'class': 'catalog-result'}):\n",
    "                 for dtag in litag.find_all('div', {'class': 'download-btn'}):\n",
    "    #                 print(dtag.span.text)\n",
    "    #                 print(dtag.a['href'])\n",
    "                    x = dtag.span.text\n",
    "                    x = x.replace('MB','')\n",
    "                    if float(x) >= 50 and float(x) <= 200:\n",
    "                        links.append(dtag.a['href'])\n",
    "    browser.quit()\n",
    "    \n",
    "    for link in links:\n",
    "        localDestination = \"./audio/audio{}.zip\".format(counter)\n",
    "        resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n",
    "        counter += 1\n",
    "        \n",
    "## Start at page 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "for i in range(1, 106):\n",
    "    zipTest = ZipFile(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}.zip'''.format(i), 'r')\n",
    "    zipTest.extractall(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}'''.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yousef\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "for i in range(1, 106):\n",
    "    files = listdir(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}'''.format(i))\n",
    "    \n",
    "    if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i)):\n",
    "        os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i))\n",
    "    \n",
    "    count = 1\n",
    "    for f in files:\n",
    "        sound = AudioSegment.from_mp3(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\audio\\audio{}\\{}'''.format(i, f))\n",
    "        out_f = sound.export(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}\\{}.wav'''.format(i, count), format=\"wav\")\n",
    "        out_f.close()\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "for i in range(1, 106):\n",
    "    files = listdir(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}'''.format(i))\n",
    "    \n",
    "    if not os.path.exists(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i)):\n",
    "        os.makedirs(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}'''.format(i))\n",
    "    \n",
    "    count1 = 1\n",
    "    total_length = 0\n",
    "    for f in files:\n",
    "        t1 = 0\n",
    "        t2 = 5000\n",
    "\n",
    "        newAudio = AudioSegment.from_wav(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs\\wav{}\\{}.wav'''.format(i, count1))\n",
    "        length = newAudio.duration_seconds * 1000\n",
    "        total_length = total_length + length\n",
    "        \n",
    "        count2 = 1\n",
    "        while t2 <= length:\n",
    "            x = newAudio[t1:t2]\n",
    "            out_f = x.export(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav{}\\{}_{}.wav'''.format(i, count1, count2), format=\"wav\")\n",
    "            out_f.close()\n",
    "            t1 = t2 #Works in milliseconds\n",
    "            t2 = t2 + 5000 # 10 seconds\n",
    "            count2 = count2 + 1\n",
    "        count1 = count1 + 1\n",
    "        if(total_length > 3600000): # one hour\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Turn Audio to Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "# import librosa\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from matplotlib.pyplot import specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_sound_files(file_paths):\n",
    "#     raw_sounds = []\n",
    "#     for fp in file_paths:\n",
    "#         X,sr = librosa.load(fp)\n",
    "#         raw_sounds.append(X)\n",
    "#     return raw_sounds\n",
    "\n",
    "\n",
    "# def plot_specgram(raw_sounds):\n",
    "# #     fig = plt.figure()\n",
    "# #     fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "#     for f in raw_sounds:\n",
    "#         plt.subplots(1)\n",
    "# #         plt.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "# #         plt.margins(x=0)\n",
    "#         specgram(np.array(f), Fs=sr)\n",
    "# #         plt.axis('tight')\n",
    "#         plt.axis('off')\n",
    "# #         plt.show()\n",
    "#         plt.savefig(\"test.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sound_file_paths = glob.glob(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav1\\*.wav''')\n",
    "\n",
    "# raw_sounds = load_sound_files(sound_file_paths[:1])\n",
    "# plot_specgram(raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmdstring = 'sox \"{}\" -n spectrogram -r -o \"{}\"'.format(r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\wavs_final\\wav1\\1_1.wav''', r'''C:\\Users\\Yousef\\PycharmProjects\\EE379K\\Voice Recognition\\voice-classification\\blah.png''')\n",
    "subprocess.call(cmdstring, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
